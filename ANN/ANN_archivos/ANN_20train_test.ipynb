{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo linrerias necesarias\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import det_curve\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7440, 63)\n"
     ]
    }
   ],
   "source": [
    "# Preparo los datos\n",
    "data = pd.read_csv('C:/Users/Universidad/Proyecto_ASMI/archivo_modificado_final.csv')\n",
    "\n",
    "# Definir el umbral de no nulos\n",
    "umbral = 0.90  \n",
    "\n",
    "# Calcular el porcentaje de valores no nulos por columna\n",
    "porcentaje_no_nulos = data.notnull().mean()\n",
    "\n",
    "# Filtrar las columnas que cumplen con el umbral\n",
    "columnas_filtradas = porcentaje_no_nulos[porcentaje_no_nulos > umbral].index\n",
    "\n",
    "# Crear un nuevo DataFrame con solo esas columnas\n",
    "df_filtrado = data[columnas_filtradas]\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(df_filtrado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7440, 63)\n"
     ]
    }
   ],
   "source": [
    "# Definir el umbral de no nulos\n",
    "umbral_filas = 0.30  \n",
    "\n",
    "# Calcular el número mínimo de valores no nulos requeridos por fila\n",
    "min_no_nulos = int(umbral_filas * df_filtrado.shape[1])\n",
    "\n",
    "# Eliminar las filas que no cumplen con el umbral\n",
    "df_filtrado_filas = df_filtrado.dropna(thresh=min_no_nulos)\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(df_filtrado_filas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saco la mediana de cada columna y la relleno en los valores nulos\n",
    "df_filtrado_filas2 = df_filtrado_filas.drop(columns=['usuario'])\n",
    "df_filtrado_filas2 = df_filtrado_filas2.fillna(df_filtrado_filas2.mean())\n",
    "df_filtrado_filas2 = df_filtrado_filas2.round(2)\n",
    "\n",
    "# Reemplazar los valores inf por nan\n",
    "df_filtrado_filas2 = df_filtrado_filas2.replace([np.inf, -np.inf], np.nan)\n",
    "# Reeemplazar los valores nan por la media de la columna\n",
    "df_filtrado_filas2 = df_filtrado_filas2.fillna(df_filtrado_filas2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 1.8983 - accuracy: 0.3738 - val_loss: 1.4848 - val_accuracy: 0.5889\n",
      "Epoch 2/30\n",
      "50/50 [==============================] - 0s 5ms/step - loss: 1.0805 - accuracy: 0.6938 - val_loss: 0.9605 - val_accuracy: 0.7435\n",
      "Epoch 3/30\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.6670 - accuracy: 0.7962 - val_loss: 0.7268 - val_accuracy: 0.7964\n",
      "Epoch 4/30\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.4886 - accuracy: 0.8519 - val_loss: 0.6565 - val_accuracy: 0.8099\n",
      "Epoch 5/30\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.3974 - accuracy: 0.8750 - val_loss: 0.6168 - val_accuracy: 0.8192\n",
      "Epoch 6/30\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.3272 - accuracy: 0.8931 - val_loss: 0.5709 - val_accuracy: 0.8351\n",
      "Epoch 7/30\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.2702 - accuracy: 0.9225 - val_loss: 0.5546 - val_accuracy: 0.8409\n",
      "Epoch 8/30\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.2522 - accuracy: 0.9212 - val_loss: 0.5483 - val_accuracy: 0.8420\n",
      "Epoch 9/30\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.2399 - accuracy: 0.9206 - val_loss: 0.5323 - val_accuracy: 0.8455\n",
      "Epoch 10/30\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.1959 - accuracy: 0.9362 - val_loss: 0.5229 - val_accuracy: 0.8553\n",
      "Epoch 11/30\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.1880 - accuracy: 0.9456 - val_loss: 0.5014 - val_accuracy: 0.8591\n",
      "Epoch 12/30\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.1611 - accuracy: 0.9481 - val_loss: 0.5278 - val_accuracy: 0.8546\n",
      "Epoch 13/30\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.1609 - accuracy: 0.9469 - val_loss: 0.5222 - val_accuracy: 0.8538\n",
      "Epoch 14/30\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.1445 - accuracy: 0.9550 - val_loss: 0.5004 - val_accuracy: 0.8644\n",
      "Epoch 15/30\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.1396 - accuracy: 0.9575 - val_loss: 0.5352 - val_accuracy: 0.8562\n",
      "Epoch 16/30\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.1195 - accuracy: 0.9650 - val_loss: 0.5218 - val_accuracy: 0.8646\n",
      "Epoch 17/30\n",
      "50/50 [==============================] - 1s 10ms/step - loss: 0.1084 - accuracy: 0.9675 - val_loss: 0.5213 - val_accuracy: 0.8658\n",
      "Epoch 18/30\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.1134 - accuracy: 0.9675 - val_loss: 0.5108 - val_accuracy: 0.8664\n",
      "Epoch 19/30\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 0.1080 - accuracy: 0.9656 - val_loss: 0.5290 - val_accuracy: 0.8671\n",
      "Epoch 20/30\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.1042 - accuracy: 0.9694 - val_loss: 0.5424 - val_accuracy: 0.8630\n",
      "Epoch 21/30\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0989 - accuracy: 0.9650 - val_loss: 0.5635 - val_accuracy: 0.8594\n",
      "Epoch 22/30\n",
      "50/50 [==============================] - 1s 12ms/step - loss: 0.0990 - accuracy: 0.9700 - val_loss: 0.5222 - val_accuracy: 0.8719\n",
      "Epoch 23/30\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0973 - accuracy: 0.9656 - val_loss: 0.5517 - val_accuracy: 0.8646\n",
      "Epoch 24/30\n",
      "50/50 [==============================] - 0s 10ms/step - loss: 0.0835 - accuracy: 0.9781 - val_loss: 0.5591 - val_accuracy: 0.8630\n",
      "Epoch 25/30\n",
      "50/50 [==============================] - 1s 13ms/step - loss: 0.0819 - accuracy: 0.9769 - val_loss: 0.5219 - val_accuracy: 0.8724\n",
      "Epoch 26/30\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0824 - accuracy: 0.9762 - val_loss: 0.5565 - val_accuracy: 0.8682\n",
      "Epoch 27/30\n",
      "50/50 [==============================] - 0s 8ms/step - loss: 0.0698 - accuracy: 0.9794 - val_loss: 0.5345 - val_accuracy: 0.8745\n",
      "Epoch 28/30\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0619 - accuracy: 0.9831 - val_loss: 0.5385 - val_accuracy: 0.8747\n",
      "Epoch 29/30\n",
      "50/50 [==============================] - 1s 14ms/step - loss: 0.0608 - accuracy: 0.9825 - val_loss: 0.5542 - val_accuracy: 0.8752\n",
      "Epoch 30/30\n",
      "50/50 [==============================] - 0s 9ms/step - loss: 0.0608 - accuracy: 0.9812 - val_loss: 0.5857 - val_accuracy: 0.8714\n",
      "183/183 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.8714\n",
      "Precisión en test: 87.14%\n",
      "Precisión para el dígito 0: 98.13%\n",
      "Precisión para el dígito 1: 97.62%\n",
      "Precisión para el dígito 2: 98.94%\n",
      "Precisión para el dígito 3: 97.65%\n",
      "Precisión para el dígito 4: 94.88%\n",
      "Precisión para el dígito 5: 95.80%\n",
      "Precisión para el dígito 6: 98.99%\n",
      "Precisión para el dígito 7: 96.63%\n",
      "Precisión para el dígito 8: 97.62%\n",
      "Precisión para el dígito 9: 98.01%\n"
     ]
    }
   ],
   "source": [
    "# Separar características y etiquetas\n",
    "X = df_filtrado_filas2.drop(columns=['usuario_num', 'muestra', 'sesion', 'digito']).values  # Todas las columnas excepto la tercera como características\n",
    "y = df_filtrado_filas2.iloc[:, 1].values  # Segunda columna como etiqueta\n",
    "\n",
    "# Normalizar características\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Codificar etiquetas\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# Primero, extraemos los identificadores únicos de los usuarios\n",
    "usuarios_unicos = df_filtrado_filas2['usuario_num'].unique()\n",
    "\n",
    "# Seleccionar aleatoriamente 20 usuarios para el entrenamiento\n",
    "np.random.seed(42)  # Para garantizar la reproducibilidad\n",
    "usuarios_entrenamiento = np.random.choice(usuarios_unicos, 20, replace=False)\n",
    "\n",
    "# Filtrar los datos para entrenamiento (solo los usuarios seleccionados)\n",
    "X_train = X[df_filtrado_filas2['usuario_num'].isin(usuarios_entrenamiento)]\n",
    "y_train = y[df_filtrado_filas2['usuario_num'].isin(usuarios_entrenamiento)]\n",
    "\n",
    "# Filtrar los datos para test (el resto de los usuarios)\n",
    "X_test = X[~df_filtrado_filas2['usuario_num'].isin(usuarios_entrenamiento)]\n",
    "y_test = y[~df_filtrado_filas2['usuario_num'].isin(usuarios_entrenamiento)]\n",
    "\n",
    "# Construir el modelo ANN\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluar el modelo\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Precisión en test: {test_acc * 100:.2f}%')\n",
    "\n",
    "# Obtener predicciones de probabilidad\n",
    "y_probs = model.predict(X_test)\n",
    "\n",
    "# Obtener las predicciones del modelo\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "\n",
    "# Calcular la precisión de cada dígito\n",
    "for i in range(10):\n",
    "    # Filtrar los valores para el dígito i\n",
    "    y_true_digit = (y_test == i)\n",
    "    y_pred_digit = (y_pred == i)\n",
    "\n",
    "    # Calcular precisión para ese dígito\n",
    "    digit_accuracy = accuracy_score(y_true_digit, y_pred_digit)\n",
    "    print(f'Precisión para el dígito {i}: {digit_accuracy * 100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ENTORNO_ASMI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
