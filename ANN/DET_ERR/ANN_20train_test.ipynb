{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importo linrerias necesarias\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import det_curve\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7440, 63)\n"
     ]
    }
   ],
   "source": [
    "# Preparo los datos\n",
    "data = pd.read_csv('../archivo_modificado_final.csv')\n",
    "\n",
    "# Definir el umbral de no nulos\n",
    "umbral = 0.90  \n",
    "\n",
    "# Calcular el porcentaje de valores no nulos por columna\n",
    "porcentaje_no_nulos = data.notnull().mean()\n",
    "\n",
    "# Filtrar las columnas que cumplen con el umbral\n",
    "columnas_filtradas = porcentaje_no_nulos[porcentaje_no_nulos > umbral].index\n",
    "\n",
    "# Crear un nuevo DataFrame con solo esas columnas\n",
    "df_filtrado = data[columnas_filtradas]\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(df_filtrado.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7440, 63)\n"
     ]
    }
   ],
   "source": [
    "# Definir el umbral de no nulos\n",
    "umbral_filas = 0.30  \n",
    "\n",
    "# Calcular el número mínimo de valores no nulos requeridos por fila\n",
    "min_no_nulos = int(umbral_filas * df_filtrado.shape[1])\n",
    "\n",
    "# Eliminar las filas que no cumplen con el umbral\n",
    "df_filtrado_filas = df_filtrado.dropna(thresh=min_no_nulos)\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(df_filtrado_filas.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saco la mediana de cada columna y la relleno en los valores nulos\n",
    "df_filtrado_filas2 = df_filtrado_filas.drop(columns=['usuario'])\n",
    "df_filtrado_filas2 = df_filtrado_filas2.fillna(df_filtrado_filas2.mean())\n",
    "df_filtrado_filas2 = df_filtrado_filas2.round(2)\n",
    "\n",
    "# Reemplazar los valores inf por nan\n",
    "df_filtrado_filas2 = df_filtrado_filas2.replace([np.inf, -np.inf], np.nan)\n",
    "# Reeemplazar los valores nan por la media de la columna\n",
    "datos_final = df_filtrado_filas2.fillna(df_filtrado_filas2.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\BiDAlab\\Proy_ASMI\\ASMI_env\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.2354 - loss: 2.1794 - val_accuracy: 0.5656 - val_loss: 1.5307\n",
      "Epoch 2/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6635 - loss: 1.2457 - val_accuracy: 0.7500 - val_loss: 1.0308\n",
      "Epoch 3/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7914 - loss: 0.7294 - val_accuracy: 0.7781 - val_loss: 0.7890\n",
      "Epoch 4/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8322 - loss: 0.5385 - val_accuracy: 0.8156 - val_loss: 0.6784\n",
      "Epoch 5/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8633 - loss: 0.4177 - val_accuracy: 0.8250 - val_loss: 0.6255\n",
      "Epoch 6/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8998 - loss: 0.3422 - val_accuracy: 0.8344 - val_loss: 0.5711\n",
      "Epoch 7/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2911 - val_accuracy: 0.8313 - val_loss: 0.5518\n",
      "Epoch 8/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9188 - loss: 0.2430 - val_accuracy: 0.8406 - val_loss: 0.5318\n",
      "Epoch 9/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9268 - loss: 0.2382 - val_accuracy: 0.8375 - val_loss: 0.5288\n",
      "Epoch 10/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9366 - loss: 0.2037 - val_accuracy: 0.8500 - val_loss: 0.5171\n",
      "Epoch 11/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9471 - loss: 0.1767 - val_accuracy: 0.8469 - val_loss: 0.4723\n",
      "Epoch 12/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9502 - loss: 0.1767 - val_accuracy: 0.8656 - val_loss: 0.4602\n",
      "Epoch 13/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9432 - loss: 0.1777 - val_accuracy: 0.8594 - val_loss: 0.4636\n",
      "Epoch 14/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9465 - loss: 0.1628 - val_accuracy: 0.8781 - val_loss: 0.4454\n",
      "Epoch 15/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9645 - loss: 0.1232 - val_accuracy: 0.8875 - val_loss: 0.4538\n",
      "Epoch 16/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9661 - loss: 0.1214 - val_accuracy: 0.8781 - val_loss: 0.4595\n",
      "Epoch 17/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9713 - loss: 0.1133 - val_accuracy: 0.8813 - val_loss: 0.4868\n",
      "Epoch 18/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9646 - loss: 0.1176 - val_accuracy: 0.8656 - val_loss: 0.4929\n",
      "Epoch 19/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9639 - loss: 0.1000 - val_accuracy: 0.8813 - val_loss: 0.4549\n",
      "Epoch 20/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9646 - loss: 0.1086 - val_accuracy: 0.8719 - val_loss: 0.4877\n",
      "Epoch 21/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9666 - loss: 0.1051 - val_accuracy: 0.8750 - val_loss: 0.4838\n",
      "Epoch 22/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9784 - loss: 0.0786 - val_accuracy: 0.8750 - val_loss: 0.4897\n",
      "Epoch 23/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9795 - loss: 0.0743 - val_accuracy: 0.8687 - val_loss: 0.4893\n",
      "Epoch 24/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9783 - loss: 0.0817 - val_accuracy: 0.8656 - val_loss: 0.5145\n",
      "Epoch 25/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9777 - loss: 0.0815 - val_accuracy: 0.8719 - val_loss: 0.4996\n",
      "Epoch 26/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9740 - loss: 0.0790 - val_accuracy: 0.8719 - val_loss: 0.5065\n",
      "Epoch 27/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9852 - loss: 0.0640 - val_accuracy: 0.8781 - val_loss: 0.4939\n",
      "Epoch 28/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9772 - loss: 0.0692 - val_accuracy: 0.8719 - val_loss: 0.5248\n",
      "Epoch 29/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9664 - loss: 0.0837 - val_accuracy: 0.8781 - val_loss: 0.4971\n",
      "Epoch 30/30\n",
      "\u001b[1m40/40\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9839 - loss: 0.0598 - val_accuracy: 0.8656 - val_loss: 0.5458\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.8687 - loss: 0.5634\n",
      "Precisión global en test: 84.73%\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 736us/step\n",
      "\n",
      "----- MATRIZ DE CONFUSIÓN GENERAL -----\n",
      "\n",
      "----- ACCURACY POR DÍGITO -----\n",
      "Accuracy para el dígito 0: 89.55%\n",
      "Accuracy para el dígito 1: 89.73%\n",
      "Accuracy para el dígito 2: 93.32%\n",
      "Accuracy para el dígito 3: 81.51%\n",
      "Accuracy para el dígito 4: 64.73%\n",
      "Accuracy para el dígito 5: 86.82%\n",
      "Accuracy para el dígito 6: 90.75%\n",
      "Accuracy para el dígito 7: 72.60%\n",
      "Accuracy para el dígito 8: 90.92%\n",
      "Accuracy para el dígito 9: 87.33%\n",
      "\n",
      "----- ACCURACY POR USUARIO -----\n",
      "\n",
      "Usuarios con peor accuracy:\n",
      "    usuario_num  accuracy  total_muestras  accuracy_porcentaje\n",
      "72          208    0.6375              80                63.75\n",
      "32          149    0.6500              80                65.00\n",
      "64          198    0.6875              80                68.75\n",
      "61          195    0.6875              80                68.75\n",
      "30          147    0.7125              80                71.25\n",
      "\n",
      "Usuarios con mejor accuracy:\n",
      "    usuario_num  accuracy  total_muestras  accuracy_porcentaje\n",
      "5           108    0.9625              80                96.25\n",
      "11          119    0.9625              80                96.25\n",
      "25          138    0.9750              80                97.50\n",
      "49          170    0.9750              80                97.50\n",
      "59          193    0.9875              80                98.75\n",
      "\n",
      "----- ANÁLISIS DET Y EER POR DÍGITO -----\n",
      "Dígito 0: EER = 0.0483, Umbral = 0.0649\n",
      "Dígito 1: EER = 0.0497, Umbral = 0.0373\n",
      "Dígito 2: EER = 0.0225, Umbral = 0.1192\n",
      "Dígito 3: EER = 0.0485, Umbral = 0.0316\n",
      "Dígito 4: EER = 0.1404, Umbral = 0.0037\n",
      "Dígito 5: EER = 0.0776, Umbral = 0.0906\n",
      "Dígito 6: EER = 0.0217, Umbral = 0.0379\n",
      "Dígito 7: EER = 0.0780, Umbral = 0.0074\n",
      "Dígito 8: EER = 0.0403, Umbral = 0.0444\n",
      "Dígito 9: EER = 0.0548, Umbral = 0.0044\n",
      "\n",
      "----- ANÁLISIS DET Y EER POR USUARIO -----\n",
      "Usuario 102: EER = 0.2353, Umbral = 0.9833\n",
      "Usuario 103: EER = 0.1333, Umbral = 0.9585\n",
      "Usuario 104: EER = 0.1000, Umbral = 0.9200\n",
      "Usuario 106: EER = 0.1857, Umbral = 0.9819\n",
      "Usuario 107: EER = 0.3077, Umbral = 0.9903\n",
      "Usuario 108: EER = 0.2078, Umbral = 0.9862\n",
      "Usuario 109: EER = 0.2698, Umbral = 0.9823\n",
      "Usuario 110: EER = 0.1806, Umbral = 0.9518\n",
      "Usuario 112: EER = 0.1818, Umbral = 0.9477\n",
      "Usuario 115: EER = 0.1867, Umbral = 0.9908\n",
      "Usuario 118: EER = 0.1667, Umbral = 0.8291\n",
      "Usuario 119: EER = 0.0649, Umbral = 0.7903\n",
      "Usuario 120: EER = 0.3125, Umbral = 0.9880\n",
      "Usuario 121: EER = 0.2308, Umbral = 0.9724\n",
      "Usuario 124: EER = 0.1200, Umbral = 0.9102\n",
      "Usuario 125: EER = 0.0526, Umbral = 0.9043\n",
      "Usuario 126: EER = 0.3016, Umbral = 0.9411\n",
      "Usuario 128: EER = 0.2857, Umbral = 0.9819\n",
      "Usuario 129: EER = 0.2267, Umbral = 0.9689\n",
      "Usuario 130: EER = 0.1818, Umbral = 0.8782\n",
      "Usuario 132: EER = 0.3684, Umbral = 0.9602\n",
      "Usuario 134: EER = 0.1642, Umbral = 0.9771\n",
      "Usuario 135: EER = 0.1351, Umbral = 0.9496\n",
      "Usuario 136: EER = 0.1667, Umbral = 0.9807\n",
      "Usuario 137: EER = 0.2500, Umbral = 0.9320\n",
      "Usuario 138: EER = 0.0385, Umbral = 0.9280\n",
      "Usuario 139: EER = 0.2676, Umbral = 0.9344\n",
      "Usuario 142: EER = 0.0423, Umbral = 0.9146\n",
      "Usuario 143: EER = 0.5294, Umbral = 0.9962\n",
      "Usuario 144: EER = 0.2615, Umbral = 0.9861\n",
      "Usuario 147: EER = 0.3913, Umbral = 0.9892\n",
      "Usuario 148: EER = 0.4286, Umbral = 0.9813\n",
      "Usuario 149: EER = 0.3462, Umbral = 0.9535\n",
      "Usuario 151: EER = 0.1579, Umbral = 0.9599\n",
      "Usuario 152: EER = 0.3500, Umbral = 0.9256\n",
      "Usuario 153: EER = 0.3194, Umbral = 0.9615\n",
      "Usuario 154: EER = 0.2143, Umbral = 0.9627\n",
      "Usuario 156: EER = 0.1733, Umbral = 0.9760\n",
      "Usuario 157: EER = 0.1846, Umbral = 0.9748\n",
      "Usuario 158: EER = 0.2500, Umbral = 0.9683\n",
      "Usuario 159: EER = 0.3077, Umbral = 0.9937\n",
      "Usuario 160: EER = 0.1061, Umbral = 0.9005\n",
      "Usuario 162: EER = 0.1884, Umbral = 0.9569\n",
      "Usuario 163: EER = 0.2500, Umbral = 0.9718\n",
      "Usuario 164: EER = 0.2031, Umbral = 0.9700\n",
      "Usuario 165: EER = 0.1642, Umbral = 0.9089\n",
      "Usuario 166: EER = 0.2143, Umbral = 0.9114\n",
      "Usuario 167: EER = 0.3000, Umbral = 0.8241\n",
      "Usuario 169: EER = 0.3000, Umbral = 0.9797\n",
      "Usuario 170: EER = 0.0769, Umbral = 0.8755\n",
      "Usuario 181: EER = 0.1765, Umbral = 0.9900\n",
      "Usuario 183: EER = 0.3125, Umbral = 0.9765\n",
      "Usuario 184: EER = 0.2308, Umbral = 0.9788\n",
      "Usuario 185: EER = 0.2143, Umbral = 0.9452\n",
      "Usuario 186: EER = 0.2586, Umbral = 0.9452\n",
      "Usuario 188: EER = 0.2500, Umbral = 0.9640\n",
      "Usuario 190: EER = 0.1429, Umbral = 0.9797\n",
      "Usuario 191: EER = 0.2353, Umbral = 0.9294\n",
      "Usuario 192: EER = 0.1818, Umbral = 0.9817\n",
      "Usuario 193: EER = 0.0253, Umbral = 0.5878\n",
      "Usuario 194: EER = 0.3636, Umbral = 0.9916\n",
      "Usuario 195: EER = 0.2182, Umbral = 0.9882\n",
      "Usuario 196: EER = 0.2222, Umbral = 0.9727\n",
      "Usuario 197: EER = 0.2353, Umbral = 0.9874\n",
      "Usuario 198: EER = 0.2545, Umbral = 0.9657\n",
      "Usuario 200: EER = 0.3235, Umbral = 0.9762\n",
      "Usuario 201: EER = 0.3125, Umbral = 0.9517\n",
      "Usuario 202: EER = 0.1765, Umbral = 0.9759\n",
      "Usuario 203: EER = 0.1818, Umbral = 0.9565\n",
      "Usuario 204: EER = 0.3077, Umbral = 0.9675\n",
      "Usuario 205: EER = 0.2113, Umbral = 0.9920\n",
      "Usuario 207: EER = 0.5333, Umbral = 0.9983\n",
      "Usuario 208: EER = 0.2414, Umbral = 0.9428\n",
      "\n",
      "----- ANÁLISIS COMPLETO -----\n",
      "Total dígitos analizados: 10\n",
      "Total usuarios analizados: 73\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import brentq\n",
    "import os\n",
    "\n",
    "# Crear directorios para guardar resultados\n",
    "os.makedirs('ANN_20train/curvas_det_digitos', exist_ok=True)\n",
    "os.makedirs('ANN_20train/curvas_det_usuarios', exist_ok=True)\n",
    "\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = datos_final.drop(columns=['usuario_num', 'muestra', 'sesion', 'digito']).values\n",
    "y = datos_final['digito'].values\n",
    "usuarios = datos_final['usuario_num'].values\n",
    "sesiones = datos_final['sesion'].values\n",
    "\n",
    "# Normalizar características\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Codificar etiquetas (si no están ya como números)\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "# Obtener la lista de usuarios únicos\n",
    "usuarios_unicos = np.unique(datos_final[\"usuario_num\"])\n",
    "\n",
    "# Seleccionar 40 usuarios aleatorios para entrenamiento\n",
    "np.random.seed(42)  # Para reproducibilidad\n",
    "usuarios_entrenamiento = np.random.choice(usuarios_unicos, size=20, replace=False)\n",
    "\n",
    "# Crear máscaras para separar datos\n",
    "# Conjunto de entrenamiento: usuarios seleccionados, da igual la sesion\n",
    "mascara_train = np.isin(usuarios, usuarios_entrenamiento)\n",
    "X_train = X[mascara_train]\n",
    "y_train = y[mascara_train]\n",
    "\n",
    "# Conjunto de test: el resto (usuarios no seleccionados)\n",
    "mascara_test = ~mascara_train\n",
    "X_test = X[mascara_test]\n",
    "y_test = y[mascara_test]\n",
    "usuarios_test = usuarios[mascara_test]\n",
    "\n",
    "# Construir el modelo ANN\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(10, activation='softmax')  # 10 clases para los dígitos 0-9\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_split=0.2, verbose=1)\n",
    "\n",
    "# Evaluar el modelo en conjunto de test\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Precisión global en test: {test_acc * 100:.2f}%')\n",
    "\n",
    "# Obtener predicciones del modelo\n",
    "y_probs = model.predict(X_test)\n",
    "y_pred = np.argmax(y_probs, axis=1)\n",
    "\n",
    "# ----- 1. Matriz de confusión general y accuracy por dígito -----\n",
    "print(\"\\n----- MATRIZ DE CONFUSIÓN GENERAL -----\")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(10)\n",
    "plt.xticks(tick_marks, range(10))\n",
    "plt.yticks(tick_marks, range(10))\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor Real')\n",
    "\n",
    "# Añadir valores en cada celda\n",
    "thresh = conf_matrix.max() / 2\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        plt.text(j, i, format(conf_matrix[i, j], 'd'),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('ANN_20train/matriz_confusion_general.png')\n",
    "plt.close()\n",
    "\n",
    "# Accuracy por dígito\n",
    "print(\"\\n----- ACCURACY POR DÍGITO -----\")\n",
    "accuracies_digito = []\n",
    "for i in range(10):\n",
    "    # Filtrar los valores para el dígito i\n",
    "    indices_digito = (y_test == i)\n",
    "    if np.sum(indices_digito) > 0:\n",
    "        acc_digito = accuracy_score(y_test[indices_digito], y_pred[indices_digito])\n",
    "        accuracies_digito.append(acc_digito)\n",
    "        print(f'Accuracy para el dígito {i}: {acc_digito * 100:.2f}%')\n",
    "    else:\n",
    "        print(f'No hay muestras para el dígito {i}')\n",
    "        accuracies_digito.append(0)\n",
    "\n",
    "# Graficar accuracy por dígito\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(10), [acc * 100 for acc in accuracies_digito])\n",
    "plt.xlabel('Dígito')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy por Dígito')\n",
    "plt.xticks(range(10))\n",
    "plt.grid(True, axis='y')\n",
    "plt.savefig('ANN_20train/accuracy_por_digito.png')\n",
    "plt.close()\n",
    "\n",
    "# ----- 2. Accuracy por usuario -----\n",
    "print(\"\\n----- ACCURACY POR USUARIO -----\")\n",
    "# Crear DataFrame para resultados por usuario\n",
    "resultados_usuario = pd.DataFrame({\n",
    "    'usuario_num': usuarios_test,\n",
    "    'real': y_test,\n",
    "    'predicho': y_pred,\n",
    "    'correcto': y_test == y_pred\n",
    "})\n",
    "\n",
    "# Calcular accuracy por usuario\n",
    "accuracies_usuario = resultados_usuario.groupby('usuario_num')['correcto'].mean()\n",
    "total_muestras = resultados_usuario.groupby('usuario_num')['correcto'].count()\n",
    "\n",
    "# Crear DataFrame con resultados\n",
    "df_accuracies = pd.DataFrame({\n",
    "    'usuario_num': accuracies_usuario.index,\n",
    "    'accuracy': accuracies_usuario.values,\n",
    "    'total_muestras': total_muestras.values\n",
    "})\n",
    "df_accuracies['accuracy_porcentaje'] = df_accuracies['accuracy'] * 100\n",
    "\n",
    "# Ordenar por accuracy (ascendente)\n",
    "df_accuracies = df_accuracies.sort_values('accuracy')\n",
    "\n",
    "# Mostrar usuarios con peor y mejor accuracy\n",
    "print(\"\\nUsuarios con peor accuracy:\")\n",
    "print(df_accuracies.head(5))\n",
    "print(\"\\nUsuarios con mejor accuracy:\")\n",
    "print(df_accuracies.tail(5))\n",
    "\n",
    "# Guardar resultados\n",
    "df_accuracies.to_csv('ANN_20train/accuracy_por_usuario.csv', index=False)\n",
    "\n",
    "# ----- 3. Función para calcular EER y curvas DET -----\n",
    "def calculate_eer(y_true, y_score):\n",
    "    \"\"\"Versión robusta del cálculo de EER que maneja casos extremos\"\"\"\n",
    "    # Verificar variabilidad en los puntajes\n",
    "    if len(np.unique(y_score)) <= 1:\n",
    "        return None, None, None, None  # No se puede calcular EER\n",
    "    \n",
    "    # Verificar variabilidad en las etiquetas\n",
    "    if len(np.unique(y_true)) <= 1:\n",
    "        return None, None, None, None  # No se puede calcular EER\n",
    "    \n",
    "    # Añadir pequeña variación a puntajes iguales para evitar problemas numéricos\n",
    "    if len(np.unique(y_score)) < len(y_score):\n",
    "        y_score = y_score + np.random.normal(0, 1e-10, len(y_score))\n",
    "    \n",
    "    try:\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_score)\n",
    "        fnr = 1 - tpr\n",
    "        \n",
    "        # Verificar si hay suficientes puntos para interpolación\n",
    "        if len(fpr) <= 2:\n",
    "            return None, None, fpr, fnr\n",
    "        \n",
    "        # Usar método más robusto para encontrar el EER\n",
    "        eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr, kind='linear', bounds_error=False, \n",
    "                                              fill_value=(0,1))(x), 0., 1., xtol=1e-8)\n",
    "        threshold = interp1d(fpr, thresholds, bounds_error=False)(eer)\n",
    "        \n",
    "        return eer, threshold, fpr, fnr\n",
    "    except Exception as e:\n",
    "        print(f\"Error en cálculo robusto de EER: {e}\")\n",
    "        return None, None, None, None\n",
    "\n",
    "def plot_det_curve(fpr, fnr, eer=None, label=None, title=None, filename=None):\n",
    "    \"\"\"Grafica la curva DET\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, fnr, 'b-', linewidth=2, label=label if label else 'Curva DET')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='EER line')\n",
    "    \n",
    "    # Marcar el punto EER si está disponible\n",
    "    if eer is not None:\n",
    "        idx_eer = np.argmin(np.abs(fpr - (1-fnr)))\n",
    "        plt.plot(fpr[idx_eer], fnr[idx_eer], 'ro', markersize=8, label=f'EER = {eer:.4f}')\n",
    "    \n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('False Negative Rate (FNR)')\n",
    "    plt.title(title if title else 'Curva DET')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    if filename:\n",
    "        plt.savefig(f\"ANN_20train/{filename}\")\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "# ----- 4. Análisis DET y EER por dígito -----\n",
    "print(\"\\n----- ANÁLISIS DET Y EER POR DÍGITO -----\")\n",
    "eers_digito = []\n",
    "digitos = []\n",
    "\n",
    "# One-vs-Rest para cada dígito\n",
    "for digito in range(10):\n",
    "    # Preparar etiquetas binarias (1 para el dígito actual, 0 para los demás)\n",
    "    y_true_bin = (y_test == digito).astype(int)\n",
    "    # Obtener probabilidades para el dígito actual\n",
    "    y_score = y_probs[:, digito]\n",
    "    \n",
    "    try:\n",
    "        # Calcular EER\n",
    "        eer, threshold, fpr, fnr = calculate_eer(y_true_bin, y_score)\n",
    "        eers_digito.append(eer)\n",
    "        digitos.append(digito)\n",
    "        \n",
    "        print(f\"Dígito {digito}: EER = {eer:.4f}, Umbral = {threshold:.4f}\")\n",
    "        \n",
    "        # Guardar curva DET para este dígito\n",
    "        plot_det_curve(\n",
    "            fpr, fnr, eer=eer,\n",
    "            label=f\"Dígito {digito} (EER={eer:.4f})\",\n",
    "            title=f\"Curva DET para Dígito {digito}\",\n",
    "            filename=f\"curvas_det_digitos/det_digito_{digito}.png\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error al calcular EER para Dígito {digito}: {e}\")\n",
    "\n",
    "# Ordenar EER por dígito\n",
    "df_eer_digito = pd.DataFrame({\n",
    "    'digito': digitos,\n",
    "    'eer': eers_digito\n",
    "})\n",
    "df_eer_digito = df_eer_digito.sort_values('eer')\n",
    "df_eer_digito.to_csv('ANN_20train/eer_por_digito_ordenado.csv', index=False)\n",
    "\n",
    "# Graficar EER por dígito (ordenado)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(df_eer_digito['digito'], df_eer_digito['eer'])\n",
    "plt.xlabel('Dígito')\n",
    "plt.ylabel('Equal Error Rate (EER)')\n",
    "plt.title('EER por Dígito (ordenado de menor a mayor)')\n",
    "plt.xticks(range(10))\n",
    "plt.grid(True, axis='y')\n",
    "plt.savefig('ANN_20train/eer_por_digito_ordenado.png')\n",
    "plt.close()\n",
    "\n",
    "# ----- 5. Análisis DET y EER por usuario -----\n",
    "print(\"\\n----- ANÁLISIS DET Y EER POR USUARIO -----\")\n",
    "eers_usuario = []\n",
    "usuarios_analizados = []\n",
    "\n",
    "# Obtener usuarios únicos en test\n",
    "usuarios_unicos_test = np.unique(usuarios_test)\n",
    "\n",
    "for usuario in usuarios_unicos_test:\n",
    "    # Filtrar datos para este usuario\n",
    "    indices_usuario = resultados_usuario['usuario_num'] == usuario\n",
    "    \n",
    "    # Verificar si hay suficientes muestras\n",
    "    if sum(indices_usuario) < 20:\n",
    "        print(f\"Usuario {usuario}: insuficientes muestras ({sum(indices_usuario)}). Omitido.\")\n",
    "        continue\n",
    "    \n",
    "    # Datos específicos del usuario\n",
    "    y_true_usuario = resultados_usuario.loc[indices_usuario, 'real'].values\n",
    "    y_pred_prob_usuario = y_probs[indices_usuario]\n",
    "    \n",
    "    # Verificar variedad de dígitos\n",
    "    if len(np.unique(y_true_usuario)) < 3:\n",
    "        print(f\"Usuario {usuario}: insuficiente variedad de dígitos. Omitido.\")\n",
    "        continue\n",
    "    \n",
    "    # Extraer confianza máxima para cada predicción\n",
    "    max_confianzas = np.max(y_pred_prob_usuario, axis=1)\n",
    "    \n",
    "    # Etiqueta binaria: si la predicción fue correcta o no\n",
    "    predicciones = np.argmax(y_pred_prob_usuario, axis=1)\n",
    "    correctas = predicciones == y_true_usuario\n",
    "\n",
    "    if len(np.unique(correctas)) < 2:\n",
    "        print(f\"Usuario {usuario}: solo una clase en etiquetas correctas. Omitido.\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Calcular curva ROC/DET\n",
    "        fpr, tpr, thresholds = roc_curve(correctas, max_confianzas)\n",
    "        fnr = 1 - tpr\n",
    "        \n",
    "        # Calcular EER\n",
    "        eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n",
    "        threshold = interp1d(fpr, thresholds)(eer)\n",
    "        \n",
    "        # Guardar resultados\n",
    "        eers_usuario.append(eer)\n",
    "        usuarios_analizados.append(usuario)\n",
    "        \n",
    "        print(f\"Usuario {usuario}: EER = {eer:.4f}, Umbral = {threshold:.4f}\")\n",
    "        \n",
    "        # Guardar curva DET para este usuario\n",
    "        plot_det_curve(\n",
    "            fpr, fnr, eer=eer,\n",
    "            label=f\"Usuario {usuario} (EER={eer:.4f})\",\n",
    "            title=f\"Curva DET para Usuario {usuario}\",\n",
    "            filename=f\"curvas_det_usuarios/det_usuario_{usuario}.png\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error al calcular EER para Usuario {usuario}: {e}\")\n",
    "\n",
    "# Ordenar EER por usuario\n",
    "df_eer_usuario = pd.DataFrame({\n",
    "    'usuario_num': usuarios_analizados,\n",
    "    'eer': eers_usuario\n",
    "})\n",
    "df_eer_usuario = df_eer_usuario.sort_values('eer')\n",
    "df_eer_usuario.to_csv('ANN_20train/eer_por_usuario_ordenado.csv', index=False)\n",
    "\n",
    "# Graficar los 10 mejores y 10 peores usuarios (por EER)\n",
    "# Mejores usuarios (menor EER)\n",
    "if len(df_eer_usuario) > 10:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    mejores = df_eer_usuario.head(10)\n",
    "    plt.bar(range(len(mejores)), mejores['eer'])\n",
    "    plt.xlabel('Usuario')\n",
    "    plt.ylabel('EER')\n",
    "    plt.title('10 Usuarios con Menor EER')\n",
    "    plt.xticks(range(len(mejores)), [f\"U{u}\" for u in mejores['usuario_num']], rotation=45)\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('ANN_20train/mejores_usuarios_eer.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Peores usuarios (mayor EER)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    peores = df_eer_usuario.tail(10)\n",
    "    plt.bar(range(len(peores)), peores['eer'])\n",
    "    plt.xlabel('Usuario')\n",
    "    plt.ylabel('EER')\n",
    "    plt.title('10 Usuarios con Mayor EER')\n",
    "    plt.xticks(range(len(peores)), [f\"U{u}\" for u in peores['usuario_num']], rotation=45)\n",
    "    plt.grid(True, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('ANN_20train/peores_usuarios_eer.png')\n",
    "    plt.close()\n",
    "\n",
    "print(\"\\n----- ANÁLISIS COMPLETO -----\")\n",
    "print(f\"Total dígitos analizados: {len(df_eer_digito)}\")\n",
    "print(f\"Total usuarios analizados: {len(df_eer_usuario)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ASMI_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
